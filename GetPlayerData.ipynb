{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Yearly Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "base_url = \"http://www.footballdb.com/players/\"\n",
    "header_names = []\n",
    "table_number = 0\n",
    "player_type = ['QB', 'RB', 'WR']\n",
    "player_columns = [16, 11, 13]\n",
    "player_file = [\"qb.csv\", \"rb.csv\", \"wr.csv\"]\n",
    "output_file = ['qb_yearly.csv', 'rb_yearly.csv', 'wr_yearly.csv']\n",
    "\n",
    "def get_header(top_row):\n",
    "    header_names = []\n",
    "    headers = top_row.find_all('th')\n",
    "    header_names.append('Name')\n",
    "    header_names.append('Pos')\n",
    "    header_names.append('CareerYear')\n",
    "    header_names.append('Ind')\n",
    "    for header in headers:\n",
    "        header_names.append(header.get_text())\n",
    "        #print(header_names)\n",
    "\n",
    "    return header_names     \n",
    "\n",
    "     \n",
    "        \n",
    "def get_row_data(data_items, full_name, year, player_page_ind):\n",
    "    data_counter = 0\n",
    "    data_values = []\n",
    "    # Get the Data Items in the row\n",
    "    data_values.append(full_name)\n",
    "    data_values.append(player_type[POS])\n",
    "    data_values.append(year)\n",
    "    data_values.append(player_page_ind)\n",
    "    for data_item in data_items:\n",
    "        if data_item.get_text() != 'NaN' and data_item.get_text() != 'NFL Totals':\n",
    "            data_values.append(data_item.get_text())\n",
    "    return data_values\n",
    "    \n",
    "POS = 2\n",
    "df = pd.read_csv(player_file[POS])\n",
    "\n",
    "\n",
    "player = df\n",
    "\n",
    "Career_Year = 0\n",
    "year_data = []\n",
    "counter = 0\n",
    "first_time = True\n",
    "\n",
    "for ind, value in player.iterrows():\n",
    "    Career_Year = 0\n",
    "    name = str(value['NAME'])\n",
    "    page = int(value['PAGE'])\n",
    "    if len(str(page)) < 2:\n",
    "        page_num = '0' + str(page) + \"/\"\n",
    "    else:\n",
    "        page_num = str(page) + \"/\"\n",
    "\n",
    "    first = name.split()[0].lower()\n",
    "    first = first.replace('.', '')\n",
    "    last = name.split()[1].lower()\n",
    "\n",
    "    full_name = last + \", \" + first\n",
    "    full_hyphen_name = first + \"-\" + last\n",
    "    ab_first = first[:2]\n",
    "    ab_last = last[:5]\n",
    "    player_page = ab_last + ab_first + page_num\n",
    "    career_year = 0\n",
    "    player_page_ind = full_hyphen_name + '-' + ab_last + ab_first+ page_num\n",
    "    current_url = base_url + player_page_ind\n",
    "    \n",
    "    print(current_url)\n",
    "\n",
    "    try:\n",
    "        sauce = urllib.request.urlopen(current_url).read()\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "        stats = soup.find_all('table')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    table_row = 0\n",
    "    header_rows = soup.find_all('thead')\n",
    "    for header_row in header_rows:\n",
    "        if 'Year' in header_row.get_text():\n",
    "            break\n",
    "        table_row = table_row + 1\n",
    "\n",
    "    top_row = header_rows[table_row]\n",
    "    if first_time == True:\n",
    "        header_val = get_header(top_row)\n",
    "        first_time = False\n",
    "        \n",
    "    #top_row = stats[table_number]\n",
    "    data_tables = stats[table_row]\n",
    "    #data_rows = stat.find_all('tr')\n",
    "    # Navigate Rows in Tables\n",
    "\n",
    "    data_rows = data_tables.find_all('tr') \n",
    "    for data_row in data_rows:\n",
    "        data_items = data_row.find_all('td')\n",
    "        print(len(data_items))\n",
    "        if len(data_items) == player_columns[POS]:\n",
    "            print(data_items)\n",
    "            if str(data_items).find('\\xa0') == -1:\n",
    "                Career_Year = Career_Year + 1\n",
    "            if str(data_items).find('NFL Totals') == -1: \n",
    "                row_data = get_row_data(data_items, full_name, Career_Year, player_page_ind)\n",
    "                print(row_data)\n",
    "                year_data.append(row_data)\n",
    "        \n",
    "print(\"Finished with processing data\")\n",
    "print(len(year_data))\n",
    "with open(output_file[POS], 'w') as mycsvfile:\n",
    "    thedatawriter = csv.writer(mycsvfile)\n",
    "    thedatawriter.writerow(header_val)\n",
    "    for row in year_data:\n",
    "        thedatawriter.writerow(row)\n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Game Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "base_url = \"http://www.footballdb.com/players/\"\n",
    "header_names = []\n",
    "table_number = 0\n",
    "player_type = ['QB', 'RB', 'WR']\n",
    "player_columns = [16, 11, 11]\n",
    "player_file = [\"qb_yearly.csv\", \"rb_yearly.csv\", \"wr_yearly.csv\"]\n",
    "output_file = ['qb_games.csv', 'rb_games.csv', 'wr_games.csv']\n",
    "#stat_type = \n",
    "stat_type = [['Pass ', 'Rush '],\n",
    "            ['Rush ', 'Rec '],\n",
    "            ['Rec ', 'Rush ']] \n",
    "pos_blanks = [[0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0]]\n",
    "POS = 0\n",
    "\n",
    "\n",
    "\n",
    "def get_header(top_row, i):\n",
    "    headers = top_row.find_all('th')\n",
    "    if i == 0:\n",
    "        header_names.append('Name')\n",
    "        header_names.append('Career Year')\n",
    "    icounter = 0\n",
    "    for header in headers:\n",
    "        if i > 0:\n",
    "            if icounter > 3:\n",
    "                header_val = stat_type[POS][i] + header.get_text()\n",
    "                header_names.append(header_val)\n",
    "        else:\n",
    "            if icounter > 3:\n",
    "                header_val = stat_type[POS][i] + header.get_text()\n",
    "                header_names.append(header_val)\n",
    "            else:    \n",
    "                header_names.append(header.get_text())\n",
    "\n",
    "\n",
    "        icounter = icounter + 1\n",
    "        #print(header_names)\n",
    "\n",
    "    return header_names     \n",
    "\n",
    "                \n",
    "    \n",
    "def get_row_data(data_items, full_name, year):\n",
    "    data_counter = 0\n",
    "    data_values = []\n",
    "    # Get the Data Items in the row\n",
    "    data_values.append(full_name)\n",
    "    data_values.append(year)\n",
    "    for data_item in data_items:\n",
    "        data_values.append(data_item.get_text())\n",
    "    return data_values\n",
    "\n",
    "    \n",
    "def get_row_data2(data_items):\n",
    "    data_counter = 0\n",
    "    data_values = []\n",
    "    # Get the Data Items in the row\n",
    "    counter = len(data_items)\n",
    "    for i in range(counter):\n",
    "        if i > 3:\n",
    "            data_values.append(data_items[i].get_text())\n",
    "    return data_values   \n",
    "\n",
    "    \n",
    "player = pd.read_csv(player_file[POS], encoding=\"utf-8\")\n",
    "#player = player.head(20)\n",
    "year_data = []\n",
    "counter = 0\n",
    "first_time = True\n",
    "row_data = []\n",
    "row_data2 = []\n",
    "\n",
    "for ind, value in player.iterrows():\n",
    "    name = str(value['Name'])\n",
    "    year = str(value['Year'])\n",
    "    CareerYr = value['CareerYear']\n",
    "    \n",
    "    web_page_ind = str(value['Ind'])\n",
    "\n",
    "    if year.isdigit() != True:\n",
    "        continue\n",
    "        \n",
    "    current_url = base_url + web_page_ind + \"gamelogs/\" + year + \"/\"\n",
    "    \n",
    "    print(current_url)\n",
    "    try:\n",
    "        sauce = urllib.request.urlopen(current_url).read()\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "    except:\n",
    "        print(\"Broke for url error\")\n",
    "        continue\n",
    "\n",
    "    alltables = soup.find_all('table')\n",
    "    if len(alltables) == 0:\n",
    "        continue\n",
    "      \n",
    "      \n",
    "    header_rows = soup.find_all('thead')\n",
    "    if len(header_rows) > 2:\n",
    "        rows = 2\n",
    "    else:\n",
    "        rows = 1\n",
    "    print(len(header_rows))\n",
    "    if first_time == True:\n",
    "        header_names = []\n",
    "        for i in range(rows):\n",
    "            print(i)\n",
    "            header_names = get_header(header_rows[i], i)\n",
    "            first_time = False\n",
    "            print(header_names)\n",
    "    \n",
    "    table = alltables[0]\n",
    "    data_rows = table.find_all('tr')\n",
    "    if rows > 1:\n",
    "        table2 = alltables[1]\n",
    "        data_rows2 = table2.find_all('tr')\n",
    "    row_count = len(data_rows)\n",
    "\n",
    "    for i in range(1, row_count):\n",
    "        print('in row %d of %d total rows' % (i, row_count))\n",
    "        data_items = data_rows[i].find_all('td')\n",
    "\n",
    "        if len(data_items) > 1:\n",
    "            row_data = get_row_data(data_items, name, CareerYr)\n",
    "        if rows > 1:\n",
    "            data_items2 = data_rows2[i].find_all('td')\n",
    "            row_data2 = get_row_data2(data_items2)\n",
    "        else:\n",
    "            row_data2 = pos_blanks[POS]\n",
    "        all_row_data = row_data + row_data2\n",
    "        print(all_row_data)\n",
    "        year_data.append(all_row_data)\n",
    "      \n",
    "      \n",
    "\n",
    "# From right script         \n",
    "print(\"Finished with processing data\")\n",
    "print(len(year_data))\n",
    "with open(output_file[POS], 'w') as mycsvfile:\n",
    "    thedatawriter = csv.writer(mycsvfile)\n",
    "    thedatawriter.writerow(header_names)\n",
    "    for row in year_data:\n",
    "        thedatawriter.writerow(row)\n",
    "\n",
    "        \n",
    "print('Done!')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
